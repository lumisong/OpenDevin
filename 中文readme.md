<p align="center">
  <img alt="OpenDevin Logo" src="./logo.png" width="150" />
</p>

# OpenDevin: Code Less, Make More : ç®€åŒ–è½¯ä»¶å¼€å‘ä»»åŠ¡å¹¶æé«˜åˆ›é€ æ•ˆç‡

[demo-video.webm](https://github.com/OpenDevin/OpenDevin/assets/38853559/5b1092cc-3554-4357-a279-c2a2e9b352ad)

## Mission ä»»åŠ¡ğŸ¯

Welcome to OpenDevin, an open-source project aiming to replicate [Devin](https://www.cognition-labs.com/introducing-devin), an autonomous AI software engineer who is capable of executing complex engineering tasks and collaborating actively with users on software development projects. This project aspires to replicate, enhance, and innovate upon Devin through the power of the open-source community.

OpenDevinï¼Œå¼€æºé¡¹ç›®ï¼Œå¤åˆ¶ Devinï¼Œä¸€ä¸ªèƒ½å¤Ÿæ‰§è¡Œå¤æ‚å·¥ç¨‹ä»»åŠ¡å¹¶ç§¯æä¸ç”¨æˆ·åœ¨è½¯ä»¶å¼€å‘é¡¹ç›®ä¸Šåˆä½œçš„è‡ªä¸»AIè½¯ä»¶å·¥ç¨‹å¸ˆã€‚å¸Œæœ›é€šè¿‡å¼€æºç¤¾åŒºçš„åŠ›é‡å¤åˆ¶ã€å¢å¼ºå¹¶åˆ›æ–° Devinã€‚

## Work in Progress è¿›å±•ğŸš§

OpenDevin is still a work in progress. But you can run the alpha version to see things working end-to-end.

OpenDevinä»åœ¨è¿›è¡Œä¸­ã€‚ä½†æ˜¯æ‚¨å¯ä»¥è¿è¡Œalphaç‰ˆæœ¬ `alpha version`ï¼Œçœ‹åˆ° `end-to-end` ç«¯åˆ°ç«¯çš„å·¥ä½œã€‚

### Requirements è¦æ±‚

* Linux, Mac OS, or [WSL on Windows](https://learn.microsoft.com/en-us/windows/wsl/install)
* [Docker](https://docs.docker.com/engine/install/)
* [Python](https://www.python.org/downloads/) >= 3.11
* [NodeJS](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) >= 14.8

### Installation å®‰è£…

First, pull our latest sandbox image [here](https://github.com/opendevin/OpenDevin/pkgs/container/sandbox)

é¦–å…ˆï¼Œ`pull` æ‹‰å–æˆ‘ä»¬ `latest` æœ€æ–°çš„ `sandbox image` æ²™ç®±é•œåƒ [è¿™é‡Œ](https://github.com/opendevin/OpenDevin/pkgs/container/sandbox)

```bash
docker pull ghcr.io/opendevin/sandbox
```

Note: you need to be able to [run `docker` without sudo](https://docs.docker.com/engine/install/linux-postinstall/)

æ³¨æ„ï¼šæ‚¨éœ€è¦èƒ½å¤Ÿ [æ— éœ€`sudo`è¿è¡Œ`docker`](https://docs.docker.com/engine/install/linux-postinstall/)

Then copy `config.toml.template` to `config.toml`. Add an OpenAI API key to `config.toml`, or see below for how to use different models.

ç„¶åå°† `config.toml.template` å¤åˆ¶åˆ° `config.toml`ã€‚å°†OpenAI APIå¯†é’¥æ·»åŠ åˆ° `config.toml`ï¼Œæˆ–æŸ¥çœ‹ä¸‹é¢å¦‚ä½•ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ã€‚

```toml
LLM_API_KEY="sk-..."
```

Next, start the backend:

æ¥ä¸‹æ¥ï¼Œå¯åŠ¨åç«¯ï¼š

```bash
python -m pip install pipenv
python -m pipenv install -v
python -m pipenv shell
uvicorn opendevin.server.listen:app --port 3000
```

If `pipenv` doesn't work for you, you can also run:

å¦‚æœ `pipenv` å¯¹æ‚¨ä¸èµ·ä½œç”¨ï¼Œæ‚¨ä¹Ÿå¯ä»¥è¿è¡Œï¼š

```bash
python -m pipenv requirements > requirements.txt && python -m pip install -r requirements.txt
```

Then, in a second terminal, start the frontend:

ç„¶åï¼Œåœ¨ç¬¬äºŒä¸ªç»ˆç«¯ä¸­ï¼Œå¯åŠ¨å‰ç«¯ï¼š

```bash
cd frontend
npm install
npm start
```

You'll see OpenDevin running at localhost:3001

æ‚¨å°†çœ‹åˆ°OpenDevinåœ¨localhost:3001ä¸Šè¿è¡Œ

1. é‡ç‚¹æ”¾åœ¨æœåŠ¡å™¨ç«¯é€»è¾‘çš„ Python å’Œå‰ç«¯å¼€å‘çš„ TypeScript ä¸Šã€‚é¡¹ç›®ä¸­å¤§é‡ä½¿ç”¨ Pythonï¼Œå‰ç«¯ä½¿ç”¨ TypeScriptã€‚
2. å¯åŠ¨åå°**ï¼šæŒ‰ç…§ README ä¸­çš„è¯´æ˜ä½¿ç”¨ pipenv å¯åŠ¨åç«¯ã€‚è¿™åŒ…æ‹¬å®‰è£…ä¾èµ–é¡¹å’Œè¿è¡ŒæœåŠ¡å™¨ã€‚
3. æ¢ç´¢ä»£ç åº“**ï¼š æ·±å…¥ Python ä»£ç åº“ï¼Œäº†è§£åç«¯ç»“æ„åŠå…¶ä¸å‰ç«¯çš„äº¤äº’æ–¹å¼ã€‚ç‰¹åˆ«æ³¨æ„æœåŠ¡å™¨çš„è®¾ç½®åŠå…¶å¤„ç†è¯·æ±‚çš„æ–¹å¼ã€‚

### Picking a Model é€‰æ‹©æ¨¡å‹

We use LiteLLM, so you can run OpenDevin with any foundation model, including OpenAI, Claude, and Gemini.

æˆ‘ä»¬ä½¿ç”¨LiteLLMï¼Œå› æ­¤æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•åŸºç¡€æ¨¡å‹è¿è¡ŒOpenDevinï¼ŒåŒ…æ‹¬OpenAIã€Claudeå’ŒGeminiã€‚

LiteLLM has a [full list of providers](https://docs.litellm.ai/docs/providers).

LiteLLMæœ‰ä¸€ä¸ª[æä¾›å•†å®Œæ•´åˆ—è¡¨](https://docs.litellm.ai/docs/providers)ã€‚

To change the model, set the `LLM_MODEL` and `LLM_API_KEY` in `config.toml`.

è¦æ›´æ”¹æ¨¡å‹ï¼Œè¯·åœ¨`config.toml`ä¸­è®¾ç½®`LLM_MODEL`å’Œ`LLM_API_KEY`ã€‚

For example, to run Claude:

ä¾‹å¦‚ï¼Œè¿è¡ŒClaudeï¼š

```toml
LLM_API_KEY="your-api-key"
LLM_MODEL="claude-3-opus-20240229"
```

You can also set the base URL for local/custom models:

æ‚¨è¿˜å¯ä»¥è®¾ç½®æœ¬åœ°/è‡ªå®šä¹‰æ¨¡å‹çš„åŸºæœ¬URLï¼š

```toml
LLM_BASE_URL="https://localhost:3000"
```

And you can customize which embeddings are used for the vector database storage:

æ‚¨å¯ä»¥è‡ªå®šä¹‰ç”¨äºå‘é‡æ•°æ®åº“å­˜å‚¨çš„åµŒå…¥ï¼š

```toml
LLM_EMBEDDING_MODEL="llama2" # can be "llama2", "openai", "azureopenai", or "local"
```

### Running on the Command Line åœ¨å‘½ä»¤è¡Œä¸Šè¿è¡Œ

You can run OpenDevin from your command line:

æ‚¨å¯ä»¥ä»å‘½ä»¤è¡Œè¿è¡ŒOpenDevinï¼š

```bash
PYTHONPATH=`pwd` python opendevin/main.py -d ./workspace/ -i 100 -t "Write a bash script that prints 'hello world'"
```

## ğŸ¤” What is [Devin](https://www.cognition-labs.com/introducing-devin)? Devin æ˜¯ä»€ä¹ˆï¼Ÿ

Devin represents a cutting-edge autonomous agent designed to navigate the complexities of software engineering. It leverages a combination of tools such as a shell, code editor, and web browser, showcasing the untapped potential of LLMs in software development. Our goal is to explore and expand upon Devin's capabilities, identifying both its strengths and areas for improvement, to guide the progress of open code models.

Devinä»£è¡¨äº†ä¸€ç§å‰æ²¿çš„è‡ªä¸»ä»£ç†ï¼Œæ—¨åœ¨è§£å†³è½¯ä»¶å·¥ç¨‹çš„å¤æ‚æ€§ã€‚å®ƒåˆ©ç”¨äº†ä¸€ç³»åˆ—å·¥å…·ï¼Œå¦‚shellã€ä»£ç ç¼–è¾‘å™¨å’ŒWebæµè§ˆå™¨ï¼Œå±•ç¤ºäº†LLMåœ¨è½¯ä»¶å¼€å‘ä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¢ç´¢å’Œæ‰©å±•Devinçš„èƒ½åŠ›ï¼Œè¯†åˆ«å…¶ä¼˜åŠ¿å’Œæ”¹è¿›é¢†åŸŸï¼Œä»¥æŒ‡å¯¼å¼€æ”¾ä»£ç æ¨¡å‹çš„è¿›å±•ã€‚

## ğŸš Why OpenDevin? ä¸ºä»€ä¹ˆæ˜¯ OpenDevin?

The OpenDevin project is born out of a desire to replicate, enhance, and innovate beyond the original Devin model. By engaging the open-source community, we aim to tackle the challenges faced by Code LLMs in practical scenarios, producing works that significantly contribute to the community and pave the way for future advancements.

OpenDeviné¡¹ç›®çš„è¯ç”Ÿæºäºå¤åˆ¶ã€å¢å¼ºå’Œåˆ›æ–°åŸå§‹Devinæ¨¡å‹çš„æ„¿æœ›ã€‚é€šè¿‡å¸å¼•å¼€æºç¤¾åŒºï¼Œæˆ‘ä»¬æ—¨åœ¨è§£å†³ä»£ç LLMåœ¨å®é™…åœºæ™¯ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œäº§ç”Ÿå¯¹ç¤¾åŒºæœ‰é‡å¤§è´¡çŒ®çš„ä½œå“ï¼Œå¹¶ä¸ºæœªæ¥çš„è¿›æ­¥é“ºå¹³é“è·¯ã€‚

## â­ï¸ Research Strategy ç ”ç©¶ç­–ç•¥

Achieving full replication of production-grade applications with LLMs is a complex endeavor. Our strategy involves:

1. **Core Technical Research:** Focusing on foundational research to understand and improve the technical aspects of code generation and handling.
2. **Specialist Abilities:** Enhancing the effectiveness of core components through data curation, training methods, and more.
3. **Task Planning:** Developing capabilities for bug detection, codebase management, and optimization.
4. **Evaluation:** Establishing comprehensive evaluation metrics to better understand and improve our models.

ä½¿ç”¨LLMå®ç°`production-grade applications`ç”Ÿäº§çº§åº”ç”¨ç¨‹åºçš„`full replication`å®Œå…¨å¤åˆ¶æ˜¯ä¸€é¡¹å¤æ‚çš„å·¥ä½œ`endeavor`ã€‚æˆ‘ä»¬çš„ç­–ç•¥`strategy`åŒ…æ‹¬ï¼š

1. **æ ¸å¿ƒæŠ€æœ¯ç ”ç©¶:** ä¸“æ³¨äºåŸºç¡€ç ”ç©¶ï¼Œä»¥`understand`äº†è§£å’Œ`improve`æ”¹è¿›ä»£ç ç”Ÿæˆå’Œå¤„ç†`code generation and handling`çš„æŠ€æœ¯æ–¹é¢ã€‚
2. **ä¸“ä¸šèƒ½åŠ›:** é€šè¿‡`data curation`æ•°æ®æ•´ç†ã€è®­ç»ƒæ–¹æ³•ç­‰æ‰‹æ®µæé«˜`core components`æ ¸å¿ƒç»„ä»¶çš„æ•ˆæœ`Enhancing the effectiveness`ã€‚
3. **ä»»åŠ¡è§„åˆ’:** å¼€å‘ç”¨äº`bug detection`é”™è¯¯æ£€æµ‹ã€`codebase management`ä»£ç åº“ç®¡ç†å’Œ`optimization`ä¼˜åŒ–çš„èƒ½åŠ›ã€‚
4. **è¯„ä¼°:** å»ºç«‹å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æ›´å¥½åœ°äº†è§£å’Œæ”¹è¿›æˆ‘ä»¬çš„æ¨¡å‹ã€‚

## ğŸ›  Technology Stack æŠ€æœ¯æ ˆ

* **Sandboxing Environment:** Ensuring safe execution of code using technologies like Docker and Kubernetes.
* **Frontend Interface:** Developing user-friendly interfaces for monitoring progress and interacting with Devin, potentially leveraging frameworks like React or creating a VSCode plugin for a more integrated experience.

* **æ²™ç®±ç¯å¢ƒ `Sandboxing Environment`:** ä½¿ç”¨Dockerå’ŒKubernetesç­‰æŠ€æœ¯ç¡®ä¿ä»£ç çš„å®‰å…¨æ‰§è¡Œ`safe execution`ã€‚
* **å‰ç«¯ç•Œé¢ `Frontend Interface`:** ä¸º`monitoring progress`ç›‘è§†è¿›åº¦å’Œä¸Devinäº¤äº’`interacting with Devin`å¼€å‘ç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼Œå¯èƒ½åˆ©ç”¨Reactç­‰æ¡†æ¶æˆ–åˆ›å»ºVSCodeæ’ä»¶`plugin`ä»¥è·å¾—æ›´ä¸€ä½“åŒ–çš„ä½“éªŒ`more integrated experience`ã€‚

Pythonã€TypeScript å’Œ Dockerã€‚

* `OpenDevin` ä½¿ç”¨ Docker ä½œä¸ºæ²™ç®±ç¯å¢ƒï¼Œè¯·ç¡®ä¿åœ¨ç³»ç»Ÿä¸­å®‰è£…äº† Dockerã€‚
* "docker pull ghcr.io/opendevin/sandbox "å‘½ä»¤æå– OpenDevin çš„æœ€æ–°æ²™ç®±æ˜ åƒ
* é…ç½®é¡¹ç›®**ï¼š å°† `config.toml.template` å¤åˆ¶åˆ° `config.toml` å¹¶æ·»åŠ  OpenAI API å¯†é’¥ã€‚è¿™ä¸€æ­¥å¯¹äºæœ¬åœ°è¿è¡Œé¡¹ç›®è‡³å…³é‡è¦ã€‚

## ğŸš€ Next Steps ä¸‹ä¸€æ­¥

An MVP demo is urgent for us. Here are the most important things to do:

* UI: a chat interface, a shell demonstrating commands, a browser, etc.
* Architecture: an agent framework with a stable backend, which can read, write and run simple commands
* Agent: capable of generating bash scripts, running tests, etc.
* Evaluation: a minimal evaluation pipeline that is consistent with Devin's evaluation.

ä¸€ä¸ªMVPæ¼”ç¤ºå¯¹æˆ‘ä»¬æ¥è¯´æ˜¯ç´§æ€¥çš„ã€‚ä»¥ä¸‹æ˜¯æœ€é‡è¦çš„äº‹æƒ…ï¼š

* UIï¼šä¸€ä¸ªèŠå¤©ç•Œé¢`chat interface`ï¼Œä¸€ä¸ª`shell demonstrating commands`æ¼”ç¤ºå‘½ä»¤çš„shellï¼Œä¸€ä¸ª`browser`æµè§ˆå™¨ç­‰ã€‚
* æ¶æ„`Architecture`ï¼šä¸€ä¸ª`stable backend`ç¨³å®šçš„åç«¯ä»£ç†æ¡†æ¶`agent framework`ï¼Œå¯ä»¥`read, write and run`è¯»å–ã€å†™å…¥å’Œè¿è¡Œç®€å•çš„å‘½ä»¤`simple commands`
* ä»£ç†`Agent`ï¼šèƒ½å¤Ÿç”Ÿæˆbashè„šæœ¬`scripts`ã€`running tests`è¿è¡Œæµ‹è¯•ç­‰ã€‚
* è¯„ä¼°`Evaluation`ï¼šä¸€ä¸ªä¸Devinçš„è¯„ä¼°`consistent`ä¸€è‡´çš„æœ€å°è¯„ä¼°ç®¡é“`minimal evaluation pipeline`ã€‚

After finishing building the MVP, we will move towards research in different topics, including foundation models, specialist capabilities, evaluation, agent studies, etc.

å®Œæˆæ„å»ºMVPåï¼Œæˆ‘ä»¬å°†æœç€ä¸åŒä¸»é¢˜çš„ç ”ç©¶æ–¹å‘å‰è¿›ï¼ŒåŒ…æ‹¬`foundation models`åŸºç¡€æ¨¡å‹ã€`specialist capabilities`ä¸“ä¸šèƒ½åŠ›ã€`evaluation`è¯„ä¼°ã€`agent studies`ä»£ç†ç ”ç©¶ç­‰ã€‚

## How to Contribute å¦‚ä½•è´¡çŒ®

OpenDevin is a community-driven project, and we welcome contributions from everyone. Whether you're a developer, a researcher, or simply enthusiastic about advancing the field of software engineering with AI, there are many ways to get involved:

* **Code Contributions:** Help us develop the core functionalities, frontend interface, or sandboxing solutions.
* **Research and Evaluation:** Contribute to our understanding of LLMs in software engineering, participate in evaluating the models, or suggest improvements.
* **Feedback and Testing:** Use the OpenDevin toolset, report bugs, suggest features, or provide feedback on usability.

For details, please check [this document](./CONTRIBUTING.md).

OpenDevinæ˜¯ä¸€ä¸ªç¤¾åŒºé©±åŠ¨çš„é¡¹ç›®`community-driven project`ï¼Œæˆ‘ä»¬æ¬¢è¿æ¯ä¸ªäººçš„è´¡çŒ®ã€‚æ— è®ºæ‚¨æ˜¯`developer`å¼€å‘äººå‘˜ã€`researcher`ç ”ç©¶äººå‘˜ï¼Œè¿˜æ˜¯å¯¹é€šè¿‡AIæ¨è¿›è½¯ä»¶å·¥ç¨‹é¢†åŸŸæ„Ÿå…´è¶£ï¼Œéƒ½æœ‰è®¸å¤šå‚ä¸çš„æ–¹å¼ï¼š

* **ä»£ç è´¡çŒ®:** å¸®åŠ©æˆ‘ä»¬å¼€å‘æ ¸å¿ƒåŠŸèƒ½`core functionalities`ã€`frontend interface`å‰ç«¯ç•Œé¢æˆ–`sandboxing solutions`æ²™ç®±è§£å†³æ–¹æ¡ˆã€‚
* **ç ”ç©¶å’Œè¯„ä¼°:** ä¸ºæˆ‘ä»¬åœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„LLMçš„ç†è§£åšå‡ºè´¡çŒ®ï¼Œå‚ä¸è¯„ä¼°æ¨¡å‹ï¼Œæˆ–æå‡ºæ”¹è¿›å»ºè®®ã€‚
* **åé¦ˆå’Œæµ‹è¯•:** ä½¿ç”¨OpenDevinå·¥å…·é›†`OpenDevin toolset`ï¼ŒæŠ¥å‘Šé”™è¯¯`report bugs`ï¼Œå»ºè®®åŠŸèƒ½`suggest features`ï¼Œæˆ–æä¾›å…³äºå¯ç”¨æ€§çš„åé¦ˆ`feedback on usability`ã€‚

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[æ­¤æ–‡æ¡£](./CONTRIBUTING.md)ã€‚

## Join Us åŠ å…¥æˆ‘ä»¬

We use Slack to discuss. Feel free to fill in the [form](https://forms.gle/758d5p6Ve8r2nxxq6) if you would like to join the Slack organization of OpenDevin. We will reach out shortly if we feel you are a good fit to the current team!

æˆ‘ä»¬ä½¿ç”¨Slackè¿›è¡Œè®¨è®ºã€‚å¦‚æœæ‚¨æƒ³åŠ å…¥OpenDevinçš„Slackç»„ç»‡ï¼Œè¯·éšæ—¶å¡«å†™[è¡¨æ ¼](https://forms.gle/758d5p6Ve8r2nxxq6)ã€‚å¦‚æœæˆ‘ä»¬è®¤ä¸ºæ‚¨é€‚åˆå½“å‰å›¢é˜Ÿï¼Œæˆ‘ä»¬å°†å¾ˆå¿«ä¸æ‚¨è”ç³»ï¼

Stay updated on OpenDevin's progress, share your ideas, and collaborate with fellow enthusiasts and experts. Together, we can make significant strides towards simplifying software engineering tasks and creating more efficient, powerful tools for developers everywhere.

éšæ—¶äº†è§£OpenDevinçš„è¿›å±•ï¼Œåˆ†äº«æ‚¨çš„æƒ³æ³•ï¼Œå¹¶ä¸å…¶ä»–çˆ±å¥½è€…å’Œä¸“å®¶åˆä½œã€‚æˆ‘ä»¬å¯ä»¥å…±åŒæœç€ç®€åŒ–è½¯ä»¶å·¥ç¨‹ä»»åŠ¡å¹¶ä¸ºå…¨çƒå¼€å‘äººå‘˜åˆ›é€ æ›´é«˜æ•ˆã€æ›´å¼ºå¤§çš„å·¥å…·è¿ˆå‡ºé‡è¦çš„ä¸€æ­¥ã€‚
